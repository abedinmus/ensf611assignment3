{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick import datasets\n",
    "X, y = datasets.loaders.load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True)\n",
    "\n",
    "# Step 3\n",
    "# Decision Tree\n",
    "dec_tree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rand_forest = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "grad_boost = GradientBoostingRegressor(max_depth=5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae5884d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Training  Validation\n",
      "Decision Tree      47.279761   73.447331\n",
      "Random Forest      29.577455   45.059351\n",
      "Gradient Boosting   3.379440   22.783221\n"
     ]
    }
   ],
   "source": [
    "# Step 4 \n",
    "def get_mse(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    cv_results_train = cross_validate(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    train_scores = -1 * cv_results_train['train_score']\n",
    "    test_scores = -1 * cv_results_train['test_score']\n",
    "    return np.mean(train_scores), np.mean(test_scores)\n",
    "\n",
    "dec_tree_train_mse, dec_tree_test_mse = get_mse(dec_tree, X_train, y_train)\n",
    "rand_forest_train_mse, rand_forest_test_mse = get_mse(rand_forest, X_train, y_train)\n",
    "grad_boost_train_mse, grad_boost_test_mse = get_mse(grad_boost, X_train, y_train)\n",
    "\n",
    "# Step 5\n",
    "results = pd.DataFrame({\n",
    "    \"Training\": [dec_tree_train_mse, rand_forest_train_mse, grad_boost_train_mse],\n",
    "    \"Validation\": [dec_tree_test_mse, rand_forest_test_mse, grad_boost_test_mse]\n",
    "}, index=['Decision Tree', \"Random Forest\", \"Gradient Boosting\"] )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Training  Validation\n",
      "Decision Tree      0.834465    0.738697\n",
      "Random Forest      0.896557    0.840927\n",
      "Gradient Boosting  0.988171    0.919471\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "def get_r2(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    cv_results_train = cross_validate(model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "    train_scores = cv_results_train['train_score']\n",
    "    test_scores = cv_results_train['test_score']\n",
    "    return np.mean(train_scores), np.mean(test_scores)\n",
    "\n",
    "dec_tree_train_r2, dec_tree_test_r2 = get_r2(dec_tree, X_train, y_train)\n",
    "rand_forest_train_r2, rand_forest_test_r2 = get_r2(rand_forest, X_train, y_train)\n",
    "grad_boost_train_r2, grad_boost_test_r2 = get_r2(grad_boost, X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Training\": [dec_tree_train_r2, rand_forest_train_r2, grad_boost_train_r2],\n",
    "    \"Validation\": [dec_tree_test_r2, rand_forest_test_r2, grad_boost_test_r2]\n",
    "}, index=['Decision Tree', \"Random Forest\", \"Gradient Boosting\"] )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. From the previous assignment, using Linear Regression I got training and test scores: mse: [110, 95], r2: [0.6, 0.62]. The non-linear models used in this assignment produced training scores of: mse: DT = [47.28, 73.44], RF = [29.58, 45.06], GB = [3.38, 22.78] and r2 scores of: DT = [0.83, 0.73], RF = [0.90, 0.84] and GB = [0.99, 0.92]. The non-linear models performed much better. I would chose the gradient boosting model for this dataset because it had the highest validation accuracy. To improve the accuracy, I would consider be to either (a) limit the maximum amount of leafs, helping to reduce the overfitting seen by the training scores compared to the validation scores or (b) modifying the minimum number of points in a node before splitting it, again to hopefully reduce overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "For this section I did not use any generative AI, I referred to the lecture slides and example notebooks on this topic. I sourced the dataset from yellowbricks. I completed the problem, in the order it was presented as it matched the sequential order of steps to perform a regression problem. I did not have many issues with this problem set as referring to the lecture notes and notebooks gave me the information I needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3     4    5     6     7     8     9      10    11  \\\n",
       "0     1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1     1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2     1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3     1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4     1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..   ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
       "173   3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174   3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175   3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176   3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177   3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       12    13  \n",
       "0    3.92  1065  \n",
       "1    3.40  1050  \n",
       "2    3.17  1185  \n",
       "3    3.45  1480  \n",
       "4    2.93   735  \n",
       "..    ...   ...  \n",
       "173  1.74   740  \n",
       "174  1.56   750  \n",
       "175  1.56   835  \n",
       "176  1.62   840  \n",
       "177  1.60   560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "\n",
    "df = pd.read_csv('wine.data',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 of type 1\n",
      "71 of type 2\n",
      "48 of type 3\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(str(df[0].value_counts()[1]) + ' of type 1')\n",
    "print(str(df[0].value_counts()[2]) + ' of type 2')\n",
    "print(str(df[0].value_counts()[3]) + ' of type 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 3 \n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True)\n",
    "\n",
    "# SVC\n",
    "svc = SVC(random_state=0)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dfc = DecisionTreeClassifier(max_depth=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "433fab90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Training  Validation\n",
      "SVC            0.680427    0.676638\n",
      "Decision Tree  0.994357    0.894017\n"
     ]
    }
   ],
   "source": [
    "# Step 4 \n",
    "def get_accuracy(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    cv_results_train = cross_validate(model, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    train_scores = cv_results_train['train_score']\n",
    "    test_scores = cv_results_train['test_score']\n",
    "    return np.mean(train_scores), np.mean(test_scores)\n",
    "\n",
    "svc_train_accuracy, svc_test_accuracy = get_accuracy(svc, X_train, y_train)\n",
    "dfc_train_accuracy, dfc_test_accuracy = get_accuracy(dfc, X_train, y_train)\n",
    "\n",
    "# Step 5\n",
    "results = pd.DataFrame({\n",
    "    \"Training\": [svc_train_accuracy, dfc_train_accuracy],\n",
    "    \"Validation\": [svc_test_accuracy, dfc_test_accuracy]\n",
    "}, index=['SVC', \"Decision Tree\"])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6660e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(168.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, dfc.predict(X_test))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0ba1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      0.95      0.93        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "It seems that Decision Tree Classifer is much more prone to overfitting compared to SVC. This is seen by the high training accuracy of DTC of 0.99 compared to its validation accuracy of 0.89. While the SVC accuracy is fairly similar with a training accuracy of 0.68 compared to its validation accuracy of 0.67. \n",
    "\n",
    "SVC models generally do not work as well as Decision Trees because they require more attention in tuning hyperparameters which are difficult to understand while Decision trees hyperparameters are easy to understand visually. Additionally Decision Trees are more simple to explain to non experts or non technical shareholders.\n",
    "\n",
    "In Step 5.2, 3 samples were incorrectly classified in the decision tree model\n",
    "\n",
    "In this dataset, I believe that maximizing precision is more important because getting a false positive in this dataset is not detrimental compared to say like a email spam detection system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "The dataset is sourced from UCI. I completed the steps in the order presented. I used generative AI to help me understand the differences between recall and precision. I entered in \"Explain the differences between recall and precision and the applications of either\". It demonstrated the formula to calculate both and significance of both metrics and when one should be wieghted higher than another in a machine learning problem. Besides my understanding of recall and precision, I did not have many challenges with programming due to the examples provided in the lecture notes and example notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "In both regression and classification models, I noticed that the standard Decision Tree models tends to overfit the data. The Gradient boosting worked the best due to having many trees work together to correct the mistakes of another tree. The tree based models hyperparameters are quite easy to understand and have simple syntax: for example max_depth simply refers to the max depth of the trees in each model. On the other hand hyperparameters of SVC are quite confusing. \n",
    "\n",
    "Using more shallow trees is better on a computational sense and by the examples in this workbook for accuracy as well. Gradient Boosting had the highest accuracy of 92% followed by Random Forest with an accuracy of 84%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "I liked learning about the different tree based models because they are some of the most popular models used in machine learning. They are quite easy to represent visually. I found challenging whether the cross_validate function needed to be tested on the test split from before but because it creates folds in the function to train and test, it is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training  Validation\n",
      "SVC  0.907812    0.910256\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lsvc = LinearSVC(max_iter=5000)\n",
    "lsvc_train_accuracy, lsvc_test_accuracy = get_accuracy(lsvc, X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Training\": lsvc_train_accuracy,\n",
    "    \"Validation\": lsvc_test_accuracy\n",
    "}, index=['SVC'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df4d8dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(168.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAHmCAYAAACmky3PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAl00lEQVR4nO3deZzO9f7/8eeMWTgzzFiz7xkq5NjpEGeUSRPVL8qoSNnLyT5ZTr5JCKdSnGz5+iYJCWM91ihlD2U5ZWwzlmSYwTDb9fvDrTlnznC4uMbnNXM97n817881n+tlbp885vO5Lp/Lx+VyuQQAAEzwdXoAAADwL4QZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAED+nB8gJyV/PcnoE5DIFw4c6PQIAL5CWEnfTx3DGDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGHOo/7vH1tVr8dYDZ76VbZtV1JSNeGLtQof8IEa9X5Xz731iTbs/ufdHxKmvfB8e+3etVYXE3/RkcPb9faoIfL393d6LBjGMeMZfk4PAM+6cClZIz6J0U9HTyl/wPX/h4ietkQnz13QhJ5PqXDBP2jOmm3qP2WhZke/qPsrlrrLE8OiZ59tp2lTx2vgoP/R4iUrdV+Napox/W8KCQlRn1ejnR4PBnHMeI6Py+VyOT2EpyV/PcvpERzz+brtWrvzkMZ2a6uo0f+rWpVLa2y3dpnbdx46rm4TP9PSt3uoVNEQSVJ6RoaWfbdPdauVV5lioc4M7rCC4UOdHsGU/T9u1tZtO/Vi59cy117uGqUPJ41WlXsbKS7upIPTwSKOmVuTlhJ308dwKTuP+VPNqvp7v2dVpFDQdbf/Y+cB1a1WPjPKkpTP11dPNKnltVFGVpUrV9C991bSipXrsqyvWLlOfn5+ahXezKHJYBXHjGeZuJR9+fJlnTt3Tj4+PipSpIgKFCjg9Ei5Vpniof91+6HjZ1S1TDHNXbtd8zfu0m+JF1WxZFH1attMDWtUvCszwrbqYVUlSbGHj2VZj4s7qatXryosrIoTY8EwjhnPcjTMs2bN0ueff66jR49mWa9atao6deqkDh06ODRZ3nUu8ZI2/Jqg+yte1F9fjFB6ukvTln2j3u/P0+fDX1LVMsWdHhEOCwktJElKungx27akpEsKDQ3Jtg7vxjHjWY6Fefz48VqxYoW6deumGjVqKDQ0VJKUkJCgH374QR9++KF+++039erVy6kR86S09HT5+vhobLd28vfLJ0maUP4pPRY9WTNXbNHol59weEJY5uPjo7z3rhTkJI4Z9zkW5kWLFmnOnDmqWLFilvXy5curdu3aatiwobp27UqYPSyoQKBKFi6UGWVJ+kP+AN1XoaR+jvvVwclgRcK585KkkEKFsm0rWDBICQkJd3kiWMcx41mOvfnr8uXLKlas2A23ly5dWhevc1kEd6biPUWUcPFytnWXSwr0N/GWAzhs/4Fr/6a96r2VsqxXrFhOAQEB2n/gZyfGgmEcM57lWJjr1q2rt956S0lJSdm2XbhwQSNHjlTDhg0dmCxve6hmFf145KRO/nYhc+3ylRTtP3ZKVcvy+jKko0dP6MefDiry8VZZ1iMff0QpKSlavXqDM4PBLI4Zz3LsFGnkyJHq3bu3GjVqpDJlyigk5NqbA86fP6/4+HjVrFlT77//vlPj5VoXLiUrNS1dkpSRkaGrqWk6e+HalYfgAoF6tP59mr16q/pN/lJDOrZSoL+/piz5WpevpKhrRGMnR4chI/46TvPnTVP/fj20YGGMate+XyOG99OkSTN05sxZp8eDQRwznuP4DUb27Nmj/fv3Z74GUbRoUdWsWVPVq1e/7X168w1Gur47RzsOHbvutpGd26ht01r6LfGSJs5fq017ftGVlFTVqFBSfZ9qoT9WK3eXp7WDG4xk16FDW0UPeU33Vq2k06fPauYnn2n0Ox8oIyPD6dFgFMfMzd3KDUYcD3NO8OYw4/YQZgB3A3f+AgAglyHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACG+Dk9QE6o98wUp0dALpMcv8npEZALla3ymNMjIA/ijBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGDIbYXZ5XJp69at+vLLLzPXkpOTPTYUAADeyu0wnzx5UpGRkXrhhRc0YsQISVJcXJzCw8P1888/e3xAAAC8idthHjNmjKpXr65vv/1Wvr7Xvr106dJq166dxowZ4/EBAQDwJn7ufsOuXbu0ZMkShYaGysfHR5Lk4+OjXr166eGHH/b0fAAAeBW3z5gTExMVHBycbd3lciktLc0jQwEA4K3cDnONGjWyvOlLkjIyMvTRRx+pevXqHhsMAABv5Pal7H79+qlbt26aP3++UlNT1b17dx08eFDnz5/X1KlTc2JGAAC8htthrl+/vpYvX645c+aoRIkS8vX11RNPPKGOHTuqZMmSOTEjAABew+0wS1KpUqU0YMAAT88CAIDXczvM0dHRN9yWnp6ucePG3dFAAAB4M7fDfPjw4SxfZ2Rk6OTJk7py5YoaNGjgscEAAPBGbod53rx5112fNWvWnc4CAIDX89iHWHTu3FmLFi3y1O4AAPBKHgtzSkqKzp0756ndAQDgldy+lD1x4sRsa6mpqfr2229Vrlw5jwwFAIC3cjvMMTEx2dby58+vqlWrql+/fh4ZCgAAb+V2mNetW5cTcwAAAN1imGNjY295h5UqVbrtYQAA8Ha3FOaIiIjMj3i8EZfLJR8fH+3fv98jgwEA4I1uKcyzZ8/O6TkAAIBuMcy3ekevwYMHc/cvAADuwG19iMXmzZu1e/dupaSkZK7Fx8dr3bp1Gjt2rMeGAwDA27gd5lmzZmns2LEqVqyYzp49q5IlS+rMmTMqW7YsnzgFAMAdcvvOX5999pk+/vhjbdq0Sf7+/lq/fr3WrVunsmXLqk6dOjkxIwAAXsPtMP/6669q1qyZJGW+U/uee+7R8OHDNXLkSM9OBwCAl3E7zMHBwYqPj5ckhYaG6uTJk5Kk8uXL6+DBg56dDh7TrkMbLVz7f9oWu0FrdizWyIlvqEixwk6PBUNmf75IDzaP1IAR72Tbtm7TFnV85S9q2OopNWvzrHr0H659+w85MCWs697rRR3/dY8+njnB6VFyLbfD3KJFC3Xq1EmXLl1SzZo1NWDAAC1fvlyjR49W8eLFc2JG3KHnuz2rkRPf0Jdzl+qph6M0ot9oNWnWQO/P5I16kC4kJqnPoDc1a+5C5Q8MyLZ947db1Tf6LdX/Yy3Nm/GBpr3/jgIDAtT1tSE6HnfSgYlhUWjhEM2eO1k9X31JV5KvOj1OruZ2mKOjo9WyZUsFBgaqX79+Onv2rPr166fFixdryJAhOTEj7tBLvTtp6fyVmjP9Cx0/GqdvN36vyRNm6I8Na6t8JT54xNstW71el5OvaP6sD1WoYHC27UtWrFXpkiX0es+XVLF8WYVVraThA/vo0uVkbdj8nQMTw6Kn/t/jCgr+g8L/9KTOn090epxcze13Zaenp2vYsGGSpMqVK2vVqlVKSEhQSEiIfH099imS8KB2zTsqIyMjy9rZM79JkkqULKZjscedGAtGNGvSQB2ebKN8+fLd8DH/uc3f79pfHS5Xjo6GXGTN6g2aNWNutr9r4D63S9q0aVMNHDhQW7ZsyVwrXLgwUTbswvlEJSVezLL254jmupJ8RQf28TqhtytbuuR/jXKHdo8p/uRpfb4oRqlpabqcfEUfzfhUhQoGKyK8+V2cFJYdOxpHlD3E7ZoOHTpUp0+fVteuXdWiRQu9//77OnbsWE7MhhzSMqKZno56QtPe/19dTLrk9DgwrkHd2ho3crAmfDhd9Vq2VcNWT2ntxm/08d9GqXixIk6PB+Q5boe5ffv2mj17tjZs2KAXXnhBX3/9tR555BFFRUVp4cKFOTEjPOjRJ/6sCR+/reWLVuvj9z5xehzkAlt3/KChb0/Us09F6rOp7+l/J7+rmvdV12uD/0cn4k85PR6Q59z29ecSJUqoS5cuWrhwoWJiYhQYGJj52rMn1a5d2+P79FbPdn5a7/79LS34dLGG9H5TLl4gxC0Y/9F0PfhADfXv3VX3V79Xf6x1v94dOVgZLpdmfDrf6fGAPOe27pUtSWlpadq0aZOWLVum9evXKyAgQFFRUZ6cTZKIh4c8HfWEhr4zQBPf+kifTP7U6XGQi/wce1TPtH0sy5q/v79KlyyhYyfiHJoKyLvcDvM333yjZcuWae3atbp8+bIefvhhjR07Vg8//LD8/NzbXf/+/W/6mPT0dHdHxH+o17iORowbrHeGTdRnMzjDgXuKFi6sw0eyvo8kNS1NcfGn1Pyhhg5NBeRdboe5a9euql27tvr27as2bdooJCTktp/8u+++U8WKFVW+fPnb3gdubtiYgdr5/Q9avWStihXP+mady5eSdflyskOTwYILiUlKTU2VJKVnZCglJVVnfzsnSQoODlLH/xepCR/N0JSZc9T6z82Vmpaq2Z8vUuLFS3ruqUgnR4choYVD5O/vL0nKl89XgYGBKl6imCQpKTFJV65w05Fb5eNy81rxkSNHVLFiRY88+aZNmzR69GjNnz9fwcHZb2wgXXuN+YcffnBrv/ffw2/xvytVtqTW7Fh8w+0fvTtNk8dPv4sT2bT7x7lOj+CYzn0GafuuvdfdNuqNfmrXppWWrFyrOfMX68ixEwoI8FdY1crq9VKU/lj7gbs8rS1lqzx28wd5iS9jZqvpnxpcd9trPaM177NFd3kim05fOHDTx7gdZk+bPn268ufPr06dOl13e61atbRnzx639kmY4S5vDjNuH2GGu24lzLf95i9Pefnll//rdnejDABAbsbtugAAMIQwAwBgyG2FOT4+Xh9++KGio6Mz17jkDADAnXM7zDt27FDr1q21atUqxcTESJKOHz+uqKgorVmzxuMDAgDgTdwO83vvvad+/fpp6dKl8vHxkSSVK1dOY8eO1eTJkz0+IAAA3sTtMB86dEgdO3aUpMwwS9Kjjz6q2NhYz00GAIAXcjvMGRkZSklJybb+66+/Zt71BQAA3B63w9y4cWONGTNGycn/uo3j4cOHNXjwYDVq1MijwwEA4G3cDnN0dLT27t2runXr6urVq6pTp47atGmjhIQEDRkyJCdmBADAa7h9569SpUrpq6++0qZNmxQbGytfX19VqlRJTZs2zfKaMwAAcN9t3ZLTx8dHzZo1U7NmzTw9DwAAXs3tMLds2fKGZ8bp6enasGHDnc4EAIDXcjvMjz32WJYwZ2RkKD4+Xlu3btWLL77o0eEAAPA2bod5wIAB113fvXu3FixYcMcDAQDgzTz2IRYPPvigdu3a5andAQDglTwW5uPHj+vChQue2h0AAF7J7UvZHTp0yPbmr5SUFMXGxqply5YeGwwAAG/kdpgrVaqULcyBgYF6+umn9fTTT3tsMAAAvJHbYR44cKCKFi2aE7MAAOD13HqNOSMjQy1atJDL5cqpeQAA8GpuhdnX11dNmjTRihUrcmoeAAC8mtuXskuUKKG3335bU6dOVbly5RQQEJBl+4QJEzw2HAAA3sbtMMfGxqpy5cqSpPPnz3t6HgAAvJrbYZ45c6b8/f2zraelpen06dMeGQoAAG/l9g1G6tWrd931y5cvq3379nc8EAAA3uyWz5i3bNmiLVu2KC0tTRMnTsy2/ejRo7py5YpHhwMAwNvccpgDAgJ05MgRpaenKyYmJtv2AgUKqH///h4dDgAAb3PLYa5bt67q1q2r9u3b64svvsjJmQAA8Fpuv8ZMlAEAyDke+3QpAABw5wgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADPFzeoCccDDhhNMjIJcpUPpPTo+AXGhx4WZOj4A8iDNmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYTZS7zwfHvt3rVWFxN/0ZHD2/X2qCHy9/d3eiwYxjEDd/jk81XlXo+r+abxah07Sy13TFLNia8osESo06PlOoTZCzz7bDtNmzpeM2fO1f01m6tnr0Hq0vk5/W3i/zg9GozimIG7wt54VtUGPaOf3/9KG5sP1O4+k1W4bjXVnztYPvlIjTt8XC6Xy+khPM0voIzTI5iy/8fN2rptp17s/Frm2stdo/ThpNGqcm8jxcWddHA6WMQxc2sWF27m9AhmhO/7u86s2aU9f/k4c61U20b649S+2tRyiBJ/POrgdHa0OT33po/h15g8rnLlCrr33kpasXJdlvUVK9fJz89PrcL5iwVZcczgdrnSM7J+nZp+7T98fByYJvcizHlc9bCqkqTYw8eyrMfFndTVq1cVFlbFibFgGMcMbseRGatUKrKhCjcIkyQF3lNYlbo/poRth5S474izw+Uyfk4P8N+cPHlSpUqVcnqMXC0ktJAkKenixWzbkpIuKTQ05G6PBOM4ZnA7fv7bIvkF5VeTpW8qIzVNvv5+Orf1oLa9MN7p0XIdx86Yk5KSNHz4cLVu3VovvfSSNm/enO0xrVu3dmAy7+Hj46O89w4D5CSOGdxI5d6RKt85XHsHztDmR4ZqW9Q4+QUXUN2Zr/PmLzc59tMaNWqUDh48qOeff17Vq1dXnz59NHdu1hfF8+D70u66hHPnJUkhhQpl21awYJASEhLu8kSwjmMG7vIvHKxqg5/RL5OW6NjsNUr66ZjOrNml3b0/UtHGNVQysqHTI+Yqjl3K3rx5s5YsWaKiRYtKkiIiIvTyyy8rNDRUERERkq79do47s//APyVJVe+tpC3fbc9cr1ixnAICArT/wM9OjQajOGbgrqDKJZUv0F8XD8VlWb90+Nq794MqlXRirFzLsTPmtLQ0BQUFZX5ds2ZNTZ48WSNGjNB3330niTNmTzh69IR+/OmgIh9vlWU98vFHlJKSotWrNzgzGMzimIG7rp45L0kKrpb1n6oGVyktSUo+/uvdHilXcyzMdevW1ahRo3Tu3Lksa+PGjVPfvn01d+5czpg9ZMRfx6ld2wj179dDFSqU1RNPPKoRw/tp0qQZOnPmrNPjwSCOGbgj+fhZnf7HTlXp9bhKP91UBSqUUOEGYXpg/Mu6fOyMTq3YfvOdIJNjNxiJi4tTz549VbNmTb399ttZtu3cuVPDhw/X4cOHtX//frf3zQ1GsuvQoa2ih7yme6tW0unTZzXzk880+p0PlJGRcfNvhlfimLk5bjDyL74FAlSld6RKt2usAmWKKeVcks59d0AH35mn5BP8Mve7W7nBiON3/rp48aKCg4Ozraenp2vXrl2qV6+e2/skzADuBsIMd+WKO39dL8qSlC9fvtuKMgAAuZnjYQYAAP9CmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADPFxuVwup4cAAADXcMYMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwizFzhx4oS6du2qBx98UI0bN9a7776rjIwMp8eCcZs2bVKTJk30+uuvOz0KcokTJ06oZ8+eatCggRo3bqxBgwbpwoULTo+V6xDmPM7lcqlPnz4qXLiwNm7cqDlz5mjFihWaNWuW06PBsGnTpmnUqFGqUKGC06MgF+nZs6dCQ0O1fv16LVmyRLGxsRo3bpzTY+U6hDmP27t3rw4ePKhhw4YpJCRElStXVrdu3TRv3jynR4NhgYGBWrBgAWHGLUtKStIDDzygAQMGKCgoSMWLF1e7du20fft2p0fLdfycHgA566efflKZMmUUGhqauXbffffpyJEjunjxooKDg50bDma98MILTo+AXKZgwYJ65513sqzFxcWpVKlSDk2Ue3HGnMclJCQoJCQky9rvXyckJDgxEgAvsHfvXs2ZM0ddunRxepRchzADADxqx44d6tq1qwYNGqTmzZs7PU6uw6XsPK5o0aI6f/58lrXfz5SLFCniwEQA8rL169dr4MCBGjlypNq0aeP0OLkSZ8x5XM2aNRUfH5/lsvWePXtUtWpVBQUFOTgZgLxm586dGjx4sD744AOifAcIcx5Xo0YN1apVS6NGjVJiYqIOHjyoqVOnKioqyunRAOQhaWlpGjZsmPr27asmTZo4PU6u5uNyuVxOD4GcderUKY0YMULff/+9goKC1LFjR/Xp08fpsWBYzZo1JV37y1aS/Pyuveq1d+9ex2aCbdu3b1dUVJQCAgKybVu5cqXKlCnjwFS5E2EGAMAQLmUDAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAO5XNOmTTVp0iRJ0uTJk9WyZcu7+vzjx4/P0ed8/vnn9frrr+fY/gFrCDOQh/Tq1Uvr1q275cd/+umnOnfuXA5OBMBdhBlwmMvlUnp6+l1/3sTERI0ePTrLJ48BcB5hBjwsNTVVYWFhmjNnjnr06KE6deqoZcuWmjZtWuZjhgwZou7du2vYsGGqXbt25odDrF69Wm3btlWtWrX08MMPa+jQoVnC+csvvygqKkp16tRReHi4YmJisjz3pEmT1LRp08yvz549q7/85S+qV6+e6tWrpx49euj48eM6cOCAmjRpovT0dLVt21aDBg2SJMXHx+vVV19VvXr1VL9+fUVFRWn79u2Z+0tJSdGoUaPUtGlT1a9fX0OHDlVKSsoNfxb9+/dXhw4dsqy5XC41b95cEyZMkCRt3LhRzzzzjOrWrasGDRrolVde0dGjR6+7vy+//FJhYWG6evVq5trXX3+tsLAwnThxQpJ09epVjR49Wg899JDq1KmjyMhIzZ8//4YzAtYQZsDD/P39JUnTpk1T9+7dtW3bNg0cOFDjx4/XypUrMx+3Z88elS9fXjt27FDt2rW1Z88e9e/fX6+++qp27NihuXPn6sSJExowYICka0Hr3bu3ChYsqI0bN2r+/Plav369EhMTbzjLwIEDdenSJa1evVobN25U/vz51b17d4WFhWnGjBmSpMWLF2vcuHHKyMhQjx49FBwcrLVr12rz5s0KDw9Xly5dMqM3c+ZMLV26VFOmTNE333yjxo0ba8GCBTd8/rZt22r37t2Z3y9J27Zt06lTp/Tkk0/q7Nmz6t27t5o3b67vvvtOa9asUXp6ugYOHHjbP/+xY8dqx44dmjNnjrZv36433nhDo0ePzvZLDGAVYQZySHh4uOrUqSM/Pz9FRETogQce0D/+8Y/M7enp6eratav8/f3l4+OjTz75RC1atFB4eLj8/f1VqlQpDRgwQJs3b9bx48e1b98+xcbGqnfv3ipUqJAKFy6sQYMG3fCM9eeff9a3336r1157TUWKFFFQUJCio6PVp0+f637P5s2bdejQIQ0bNkwhISEKDAxUly5dVKFCBX355ZeSpJiYGLVp00a1atVSQECAHn/8cT344IM3/Bk0bdpUxYsX14oVKzLXYmJiVKdOHVWuXFnFihXTli1b1KNHD/n7+6tQoUJ69NFHtW/fvsyPnHTHpUuXNG/ePL366quqUKGC8uXLp8aNG+vJJ5/U559/7vb+ACf4OT0AkFdVqVIly9dly5bVqVOnMr8uXbq08uXLl/n14cOH9c9//jPzs5B/ly9fPp04cUJJSUmSpHLlymVuu+eeexQUFHTd5z9y5Mh1H//YY49d9/GHDx+Wy+VSo0aNsqy7XC7FxcVJunap+9/3J0mVK1fOfK7/lC9fPkVGRmr58uV65ZVXlJqaqlWrVql///6Zj1m4cKEWLFig+Ph4paamKiMjQ+np6UpPT8/8HOhbdezYMaWlpalPnz7y8fHJ8mcoUaKEW/sCnEKYgRySkZGR5WuXy6X8+fNnfv2fHyjv6+ur9u3b680337zu/pYuXSpJWYJzvee52Rw34uvrq/z58+uHH3644WNSUlKyPf/NzmzbtWunmTNnKjY2VkeOHNGVK1cyfzmIiYnRmDFjNGbMGEVERCgwMFALFizQ0KFDb2lm6drP9Xe/z/bZZ5+pVq1at7wPwBIuZQM5JDY2NsvXJ06cUKlSpW74+EqVKunHH3/MspacnKwzZ85IUub3/n72+vs+k5OTr7u/ihUrSrp2Jvy7X3/9VTNmzLju69KVKlXSlStX9Msvv2RZP378eGb8SpYsmeX1YknZHv+fwsLCVL16da1atUrLli1Tq1atFBwcLEnauXOnKlasqHbt2ikwMFCSMt8Idz2//2KTmpqaufbvP4/y5cvLz89P+/bty/J9p06d+q9vUgMsIcxADlm9erW2b9+u1NRULV++XD/++KPatGlzw8d37txZe/fu1SeffKLk5GQlJCTor3/9q7p06aKMjAzVqlVLxYsX19///nclJSXp3LlzGj9+fJaz8H9XtWpVNWrUSO+9957OnDmjy5cva8KECfriiy8UHBysAgUKSLoW7sTERDVt2lTVqlXTm2++qZMnTyotLU3Lly9XRERE5ll0q1attGzZMu3fv18pKSn66quvdODAgZv+LNq1a6c1a9Zo/fr1euqppzLXy5QpozNnzujIkSNKSUnRrFmzdOjQIUnXLptf788kSevXr5cknTlzRosWLcrc/oc//EEdOnTQxx9/rD179igjI0P79u3Tc889p1mzZt10TsACwgzkkE6dOmnq1KmqX7++xo8fr+joaDVu3PiGj69Vq5bee+89ffXVV2rYsKFat26t5ORkTZ8+Xb6+vgoICND06dN1+vRpNWvWTM8884z+/Oc/q2TJkje8nPzuu++qSJEiioiIULNmzZSQkKBp06bJ19dXNWrUUOPGjdW/f39FR0fL19dXU6ZMUUhIiCIjI1WvXj1NmzZNEydOzHyDV9++fRUeHq6XXnpJTZo00ffff6/nn38+yxns9URGRmr//v0qWLBgltewn3vuOT300EN68skn1aJFC509e1ZTpkxRtWrV1KFDB/30009Z9lOtWjX17dtXY8eO1SOPPKIhQ4bo5ZdflqTMfws+aNAgPfLII+rVq5dq166tvn37qn379pmPA6zzcf37CzQAPCIsLEzvvPNOlrNDALgVnDEDAGAIYQYAwBAuZQMAYAhnzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADPn//4yaR9eHJCQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test, lsvc.predict(X_test))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4509a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      1.00      0.94        16\n",
      "           2       1.00      0.86      0.92        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.95      0.94        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lsvc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "It performed higher than the Decision Tree model with a validation accuracy of 0.91 anda f1-score of 0.94 with also 3 incorrectly classified samples. I believe that LinearSVC is a good model for this dataset as it did not overfit as much as the Decision Tree classfier and it seems to perform well on high-dimensional datasets such as this one with 13 features/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
